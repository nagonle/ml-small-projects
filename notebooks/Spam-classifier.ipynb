{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spam.py\n",
    "from nltk import word_tokenize, NaiveBayesClassifier\n",
    "from nltk import classify\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "#from sklearn.lda import LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import random\n",
    "import os, glob, re\n",
    "import numpy\n",
    "print \"Imports Done !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions for text processing\n",
    "wordlemmatizer = WordNetLemmatizer()\n",
    "commonwords = stopwords.words('english')\n",
    "\n",
    "def NLTK_extractor(email):\n",
    "\tfeatures =  {}\n",
    "\twordtokens = [ wordlemmatizer.lemmatize(word.lower()) for word in word_tokenize(email.decode('utf-8', 'ignore')) ]\n",
    "\tfor word in wordtokens:\n",
    "\t\tif word not in commonwords:\n",
    "\t\t\tfeatures[word] = True\n",
    "\treturn features\n",
    "\n",
    "def word_extractor(email):\n",
    "\twords =  \"\"\n",
    "\twordtokens = [ wordlemmatizer.lemmatize(word.lower()) for word in word_tokenize(email.decode('utf-8', 'ignore')) ]\n",
    "\tfor word in wordtokens:\n",
    "\t\tif word not in commonwords:\n",
    "\t\t\twords += word\n",
    "\t\t\twords += \" \"\n",
    "\treturn words\n",
    "\n",
    "def printScores(scores,nSPAM):\n",
    "\tif(scores[3][0]==nSPAM):\n",
    "\t\tlabel1 = 'Spam'\n",
    "\t\tlabel2 = 'Ham'\n",
    "\telse:\n",
    "\t\tlabel2 = 'Spam'\n",
    "\t\tlabel1 = 'Ham'\n",
    "\n",
    "\tprint \"Precision %s = %f\"%(label1,scores[0][0])\n",
    "\tprint \"Precision %s = %f\"%(label2,scores[0][1])\n",
    "\tprint \"Recall %s = %f\"%(label1,scores[1][0])\n",
    "\tprint \"Recall %s = %f\"%(label2,scores[1][1])\n",
    "\tprint \"F-Measure %s = %f\"%(label1,scores[2][0])\n",
    "\tprint \"F-Measure %s = %f\"%(label2,scores[2][1])\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import ham/spam emails.\n",
    "\n",
    "SEED = 448\n",
    "random.seed(SEED)\n",
    "hamtexts = []\n",
    "spamtexts = []\n",
    "\n",
    "for filename in glob.glob(\"enron-dataset/small-collection/ham/*.txt\"):\n",
    "    find = open(filename)\n",
    "    hamtexts.append(find.read())\n",
    "    find.close()\n",
    "    \n",
    "for filename in glob.glob(\"enron-dataset/small-collection/spam/*.txt\"):\n",
    "    find = open(filename)\n",
    "    spamtexts.append(find.read())\n",
    "    find.close()\t\n",
    "\n",
    "emails = [(email,'spam') for email in spamtexts]\n",
    "emails += [(email,'ham') for email in hamtexts]\n",
    "random.shuffle(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing train/test sets.\n",
    "examples = [(word_extractor(email), label) for (email, label) in emails]\n",
    "size_test = int(len(examples)*0.9)\n",
    "train_set, test_set = examples[size_test:], examples[:size_test]\n",
    "print \"train_set size = %d, test_set size = %d\" % (len(train_set),len(test_set))\n",
    "nspam_train = sum([example[1]=='spam' for example in train_set])\n",
    "nham_train = sum([example[1]=='ham' for example in train_set])\n",
    "nspam_test = sum([example[1]=='spam' for example in test_set])\n",
    "nham_test = sum([example[1]=='ham' for example in test_set])\n",
    "print \"n_spam train_set = %d, n_ham train_set = %d (%f%%)\" % (nspam_train,nham_train,100*nham_train/(nspam_train+nham_train))\n",
    "print \"n_spam test_set = %d, n_ham test_set = %d  (%f%%)\" % (nspam_test,nham_test,100*nham_test/(nspam_test+nham_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limitngrams = 1\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, limitngrams), binary='False')\n",
    "x = count_vectorizer.fit_transform(numpy.asarray([example[0] for example in train_set]))\n",
    "y = numpy.asarray([example[1] for example in train_set])\n",
    "\n",
    "xt = count_vectorizer.transform(numpy.asarray([example[0] for example in test_set]))\n",
    "yt = numpy.asarray([example[1] for example in test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MultinomialNB()\n",
    "#classifier = MultinomialNB(class_prior=[0.5,0.5])\n",
    "#classifier = BernoulliNB()\n",
    "\n",
    "classifier.fit(x,y)\n",
    "\n",
    "acc = classifier.score(xt,yt)\n",
    "print \"Classificaction Accuracy NB (TEST) : %f\"%acc\n",
    "ypred = classifier.predict(xt)\n",
    "scores = precision_recall_fscore_support(yt, ypred)\n",
    "ntestSPAM = sum(yt == 'spam')\n",
    "printScores(scores,ntestSPAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_transformer = TfidfTransformer(use_idf=False).fit(x)\n",
    "x_train_tfidf = tf_transformer.transform(x)\n",
    "x_test_tfidf = tf_transformer.transform(xt)\n",
    "scaler = preprocessing.StandardScaler(with_mean=False).fit(x_train_tfidf)\n",
    "\n",
    "x_train_tfidf = scaler.transform(x_train_tfidf)\n",
    "x_test_tfidf = scaler.transform(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model = model.fit(x_train_tfidf, y)\n",
    "acc = model.score(x_test_tfidf,yt)\n",
    "print \"Classificaction Accuracy LOGIT (TEST) : %f\"%acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'you are the winner !! congrats. your prize is only a one transaction of distance from you'\n",
    "text_tfidf = scaler.transform(tf_transformer.transform(count_vectorizer.transform(numpy.asarray([word_extractor(text)]))))\n",
    "\n",
    "print model.predict(text_tfidf)\n",
    "print model.predict_proba(text_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearDiscriminantAnalysis()\n",
    "model = model.fit(x_train_tfidf.toarray(), y)\n",
    "acc = model.score(x_test_tfidf.toarray(),yt)\n",
    "print \"Classificaction Accuracy LDA (TEST) : %f\"%acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuadraticDiscriminantAnalysis()\n",
    "model = model.fit(x_train_tfidf.toarray(), y)\n",
    "acc = model.score(x_test_tfidf.toarray(),yt)\n",
    "print \"Classificaction Accuracy QDA (TEST) : %f\"%acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
